\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Assignment 2 Chapter3},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Assignment 2 Chapter3}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{}
    \preauthor{}\postauthor{}
    \date{}
    \predate{}\postdate{}
  

\begin{document}
\maketitle

\hypertarget{section}{%
\subsection{}\label{section}}

\hypertarget{a}{%
\subsubsection{(4.a)}\label{a}}

If the irreducible error is large, then I think polynominal regression
will have a better fit, which means data get large RSS. In the other
hand, if the irreducible error is small, linear regression will have a
better fit, smaller RSS.

\hypertarget{b}{%
\subsubsection{(4.b)}\label{b}}

Polynominal regression will have a higher testing RSS due to the
overfitting.

\hypertarget{c}{%
\subsubsection{(4.c)}\label{c}}

Polynominal regression will perform better, having a lower RSS than
linear regression. Since polynomincal regression is more flexible than
the linear one, which means it can fit the unknown relationship of data
pretty well to reduce the RSS.

\hypertarget{d}{%
\subsubsection{(4.d)}\label{d}}

Basically, it's the bias-variance tradeoff in Chap.2. Since we don't
know how far it is from linear, there will be two possible answers. If
the data is close to linear regression, linear regression will have a
smaller testing RSS. Otherwise, if the data is far from linear
regression, polynominal regression will have a samller testing RSS.

\hypertarget{a-1}{%
\subsubsection{(9.a)}\label{a-1}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{require}\NormalTok{(ISLR)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: ISLR
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(Auto)}
\KeywordTok{pairs}\NormalTok{(Auto)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-2-1.pdf}

\hypertarget{b-1}{%
\subsubsection{(9.b)}\label{b-1}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor}\NormalTok{(}\KeywordTok{subset}\NormalTok{(Auto, }\DataTypeTok{select=}\OperatorTok{-}\NormalTok{name))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     mpg  cylinders displacement horsepower     weight
## mpg           1.0000000 -0.7776175   -0.8051269 -0.7784268 -0.8322442
## cylinders    -0.7776175  1.0000000    0.9508233  0.8429834  0.8975273
## displacement -0.8051269  0.9508233    1.0000000  0.8972570  0.9329944
## horsepower   -0.7784268  0.8429834    0.8972570  1.0000000  0.8645377
## weight       -0.8322442  0.8975273    0.9329944  0.8645377  1.0000000
## acceleration  0.4233285 -0.5046834   -0.5438005 -0.6891955 -0.4168392
## year          0.5805410 -0.3456474   -0.3698552 -0.4163615 -0.3091199
## origin        0.5652088 -0.5689316   -0.6145351 -0.4551715 -0.5850054
##              acceleration       year     origin
## mpg             0.4233285  0.5805410  0.5652088
## cylinders      -0.5046834 -0.3456474 -0.5689316
## displacement   -0.5438005 -0.3698552 -0.6145351
## horsepower     -0.6891955 -0.4163615 -0.4551715
## weight         -0.4168392 -0.3091199 -0.5850054
## acceleration    1.0000000  0.2903161  0.2127458
## year            0.2903161  1.0000000  0.1815277
## origin          0.2127458  0.1815277  1.0000000
\end{verbatim}

\hypertarget{c-1}{%
\subsubsection{(9.c)}\label{c-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit=}\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{.}\OperatorTok{-}\NormalTok{name, }\DataTypeTok{data=}\NormalTok{Auto)}
\KeywordTok{summary}\NormalTok{(lm.fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = mpg ~ . - name, data = Auto)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -9.5903 -2.1565 -0.1169  1.8690 13.0604 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -17.218435   4.644294  -3.707  0.00024 ***
## cylinders     -0.493376   0.323282  -1.526  0.12780    
## displacement   0.019896   0.007515   2.647  0.00844 ** 
## horsepower    -0.016951   0.013787  -1.230  0.21963    
## weight        -0.006474   0.000652  -9.929  < 2e-16 ***
## acceleration   0.080576   0.098845   0.815  0.41548    
## year           0.750773   0.050973  14.729  < 2e-16 ***
## origin         1.426141   0.278136   5.127 4.67e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.328 on 384 degrees of freedom
## Multiple R-squared:  0.8215, Adjusted R-squared:  0.8182 
## F-statistic: 252.4 on 7 and 384 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  F-stat is 252.4, far from 1. And p value is way smaller. Therefore,
  there is a relationship between response and predictors.
\item
  Displacement, weight, year, and origin have a relatively smaller p
  value than the other predictors, which means they get a very strong
  relationship to the response.
\item
  For year variable, mpg will go up 0.75 for 1 year, which is positive
  relationship.
\end{enumerate}

\hypertarget{d-1}{%
\subsubsection{(9.d)}\label{d-1}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(lm.fit)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-5-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{rstudent}\NormalTok{(lm.fit))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-5-2.pdf}
From the leverage plot, point 14 appears to have high leverage. And from
studentized residual plot, there are a few plots exceed value 3,
outliers possiblly.

\hypertarget{e}{%
\subsubsection{(9.e)}\label{e}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit1=}\StringTok{ }\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\NormalTok{displacement}\OperatorTok{*}\NormalTok{horsepower}\OperatorTok{+}\NormalTok{horsepower}\OperatorTok{*}\NormalTok{weight, }\DataTypeTok{data=}\NormalTok{Auto)}
\KeywordTok{summary}\NormalTok{(lm.fit1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = mpg ~ displacement * horsepower + horsepower * weight, 
##     data = Auto)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.7636  -2.2071  -0.3269   1.9714  16.1650 
## 
## Coefficients:
##                           Estimate Std. Error t value Pr(>|t|)    
## (Intercept)              5.730e+01  2.889e+00  19.835  < 2e-16 ***
## displacement            -5.688e-02  1.568e-02  -3.628 0.000324 ***
## horsepower              -2.204e-01  2.828e-02  -7.794 6.09e-14 ***
## weight                  -4.712e-03  1.836e-03  -2.566 0.010667 *  
## displacement:horsepower  3.823e-04  1.112e-04   3.438 0.000650 ***
## horsepower:weight        1.510e-05  1.302e-05   1.160 0.246734    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.874 on 386 degrees of freedom
## Multiple R-squared:  0.7568, Adjusted R-squared:  0.7536 
## F-statistic: 240.2 on 5 and 386 DF,  p-value: < 2.2e-16
\end{verbatim}

Wow, the interaction of displacement and horsepower is statistically
significant. However, the interaction of horsepower and weight is not
significant at all, p value is pretty big, and the 95\% confidence level
of estimate is possibly 0.

\hypertarget{e-1}{%
\subsubsection{(9.e)}\label{e-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit2=}\StringTok{ }\KeywordTok{lm}\NormalTok{(mpg}\OperatorTok{~}\KeywordTok{log}\NormalTok{(displacement)}\OperatorTok{+}\NormalTok{horsepower}\OperatorTok{+}\KeywordTok{I}\NormalTok{(horsepower}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\NormalTok{weight, }\DataTypeTok{data=}\NormalTok{Auto)}
\KeywordTok{summary}\NormalTok{(lm.fit2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = mpg ~ log(displacement) + horsepower + I(horsepower^2) + 
##     weight, data = Auto)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.3898  -2.4319  -0.0006   1.9372  15.2646 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(>|t|)    
## (Intercept)       67.3110290  3.9138964  17.198  < 2e-16 ***
## log(displacement) -3.5781577  1.1243186  -3.183  0.00158 ** 
## horsepower        -0.2549495  0.0359410  -7.094 6.26e-12 ***
## I(horsepower^2)    0.0007726  0.0001206   6.406 4.35e-10 ***
## weight            -0.0028401  0.0007208  -3.940 9.67e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.952 on 387 degrees of freedom
## Multiple R-squared:  0.7463, Adjusted R-squared:  0.7437 
## F-statistic: 284.6 on 4 and 387 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(lm.fit2)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-7-1.pdf}
I log displacement and square horsepower. It seems like all the four
paremeters have pretty significant importance for mpg. The residual plot
is close to linear regression. But from the rest of plot, we can observe
that there are still a few outliers and leverage point. And as the
Normal Q-Q shows, there are some noises in the distribution of
residuals. To address these issuee, maybe, it's cause by the non-linear
relationship between each parameters and mpg. so let's try log mpg.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit3=}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\KeywordTok{log}\NormalTok{(mpg)}\OperatorTok{~}\KeywordTok{log}\NormalTok{(displacement)}\OperatorTok{+}\NormalTok{horsepower}\OperatorTok{+}\KeywordTok{I}\NormalTok{(horsepower}\OperatorTok{^}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\NormalTok{weight, }\DataTypeTok{data=}\NormalTok{Auto)}
\KeywordTok{summary}\NormalTok{(lm.fit3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = log(mpg) ~ log(displacement) + horsepower + I(horsepower^2) + 
##     weight, data = Auto)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.48179 -0.09582 -0.00280  0.09862  0.54895 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(>|t|)    
## (Intercept)        4.736e+00  1.507e-01  31.427  < 2e-16 ***
## log(displacement) -1.196e-01  4.329e-02  -2.763 0.006000 ** 
## horsepower        -7.230e-03  1.384e-03  -5.225 2.86e-07 ***
## I(horsepower^2)    1.773e-05  4.644e-06   3.818 0.000157 ***
## weight            -1.642e-04  2.776e-05  -5.915 7.30e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.1522 on 387 degrees of freedom
## Multiple R-squared:  0.8018, Adjusted R-squared:  0.7998 
## F-statistic: 391.4 on 4 and 387 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(lm.fit3)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-8-1.pdf}
After we log mpg, we can see that the outliers and leverage points
become less. And the Normal Q-Q is kind of linear, which means the noise
in residual has been decreased.

\hypertarget{a-2}{%
\subsubsection{(14.a)}\label{a-2}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{x1 =}\StringTok{ }\KeywordTok{runif}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{x2 =}\StringTok{ }\FloatTok{0.5} \OperatorTok{*}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{)}\OperatorTok{/}\DecValTok{10}
\NormalTok{y =}\StringTok{ }\DecValTok{2} \OperatorTok{+}\StringTok{ }\DecValTok{2}\OperatorTok{*}\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\FloatTok{0.3}\OperatorTok{*}\NormalTok{x2 }\OperatorTok{+}\StringTok{ }\KeywordTok{rnorm}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Y=2+2X1+0.3X2+ϵ β0=2,β1=2,β3=0.3

\hypertarget{b-2}{%
\subsubsection{(14.b)}\label{b-2}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor}\NormalTok{(x1, x2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8351212
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(x1, x2)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-10-1.pdf}

\hypertarget{c-2}{%
\subsubsection{(14.c)}\label{c-2}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit =}\StringTok{ }\KeywordTok{lm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x1}\OperatorTok{+}\NormalTok{x2)}
\KeywordTok{summary}\NormalTok{(lm.fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8311 -0.7273 -0.0537  0.6338  2.3359 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.1305     0.2319   9.188 7.61e-15 ***
## x1            1.4396     0.7212   1.996   0.0487 *  
## x2            1.0097     1.1337   0.891   0.3754    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.056 on 97 degrees of freedom
## Multiple R-squared:  0.2088, Adjusted R-squared:  0.1925 
## F-statistic:  12.8 on 2 and 97 DF,  p-value: 1.164e-05
\end{verbatim}

β0=2.13,β1=1,43,β3=1.01. The p value for estimate for x1 and x2 is kind
of high, representing insignificant. But these two numbers are still
below the 5\%, thus, we can reject the null hypothesis for these two
parameters. But I don't think the regression coefficients are close to
true data, since R-squared is only 20\%, and the p value for each
coefficinets is too high.

\hypertarget{d-2}{%
\subsubsection{(14.d)}\label{d-2}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit =}\StringTok{ }\KeywordTok{lm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x1)}
\KeywordTok{summary}\NormalTok{(lm.fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.89495 -0.66874 -0.07785  0.59221  2.45560 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.1124     0.2307   9.155 8.27e-15 ***
## x1            1.9759     0.3963   4.986 2.66e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.055 on 98 degrees of freedom
## Multiple R-squared:  0.2024, Adjusted R-squared:  0.1942 
## F-statistic: 24.86 on 1 and 98 DF,  p-value: 2.661e-06
\end{verbatim}

We can surly reject the null hypothesis for x1, since the p value is so
low, which means it has the significant importance to the y.

\hypertarget{e-2}{%
\subsubsection{(14.e)}\label{e-2}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit =}\StringTok{ }\KeywordTok{lm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x2)}
\KeywordTok{summary}\NormalTok{(lm.fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.62687 -0.75156 -0.03598  0.72383  2.44890 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.3899     0.1949   12.26  < 2e-16 ***
## x2            2.8996     0.6330    4.58 1.37e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.072 on 98 degrees of freedom
## Multiple R-squared:  0.1763, Adjusted R-squared:  0.1679 
## F-statistic: 20.98 on 1 and 98 DF,  p-value: 1.366e-05
\end{verbatim}

We can surly reject the null hypothesis for x2, since the p value is so
low, which means it has the significant importance to the y.

\hypertarget{f}{%
\subsubsection{(14.f)}\label{f}}

No, honestly, because of the colinearity of x1 x2, therefore, the 14.d
and 14.e summaries are able to support that x1 and x2 are relevent to y
respectively. Due to colinearity, 14.c summury shows that none of x1 and
x2 have a pretty significant importance for y.

\hypertarget{g}{%
\subsubsection{(14.g)}\label{g}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x1 =}\StringTok{ }\KeywordTok{c}\NormalTok{(x1, }\FloatTok{0.1}\NormalTok{)}
\NormalTok{x2 =}\StringTok{ }\KeywordTok{c}\NormalTok{(x2, }\FloatTok{0.8}\NormalTok{)}
\NormalTok{y =}\StringTok{ }\KeywordTok{c}\NormalTok{(y, }\DecValTok{6}\NormalTok{)}
\NormalTok{lm.fit1 =}\StringTok{ }\KeywordTok{lm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x1}\OperatorTok{+}\NormalTok{x2)}
\KeywordTok{summary}\NormalTok{(lm.fit1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x1 + x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.73348 -0.69318 -0.05263  0.66385  2.30619 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.2267     0.2314   9.624 7.91e-16 ***
## x1            0.5394     0.5922   0.911  0.36458    
## x2            2.5146     0.8977   2.801  0.00614 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.075 on 98 degrees of freedom
## Multiple R-squared:  0.2188, Adjusted R-squared:  0.2029 
## F-statistic: 13.72 on 2 and 98 DF,  p-value: 5.564e-06
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit2 =}\StringTok{ }\KeywordTok{lm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x1)}
\KeywordTok{summary}\NormalTok{(lm.fit2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.8897 -0.6556 -0.0909  0.5682  3.5665 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.2569     0.2390   9.445 1.78e-15 ***
## x1            1.7657     0.4124   4.282 4.29e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.111 on 99 degrees of freedom
## Multiple R-squared:  0.1562, Adjusted R-squared:  0.1477 
## F-statistic: 18.33 on 1 and 99 DF,  p-value: 4.295e-05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.fit3 =}\StringTok{ }\KeywordTok{lm}\NormalTok{(y}\OperatorTok{~}\NormalTok{x2)}
\KeywordTok{summary}\NormalTok{(lm.fit3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.64729 -0.71021 -0.06899  0.72699  2.38074 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   2.3451     0.1912  12.264  < 2e-16 ***
## x2            3.1190     0.6040   5.164 1.25e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.074 on 99 degrees of freedom
## Multiple R-squared:  0.2122, Adjusted R-squared:  0.2042 
## F-statistic: 26.66 on 1 and 99 DF,  p-value: 1.253e-06
\end{verbatim}

In the regression with both x1 and x2, the coefficient of x2 becomes
statistical significance.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(lm.fit1)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-16-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(lm.fit2)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-16-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(lm.fit3)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-16-3.pdf}
In first and third model, there is a relatively high leverage point.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{rstudent}\NormalTok{(lm.fit1))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-17-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{rstudent}\NormalTok{(lm.fit2))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-17-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\KeywordTok{rstudent}\NormalTok{(lm.fit3))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-17-3.pdf}
In seconde model, there is an outlier out of value 3.

\hypertarget{a-3}{%
\subsubsection{(15.a)}\label{a-3}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{require}\NormalTok{(MASS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: MASS
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(Boston)}
\NormalTok{Boston}\OperatorTok{$}\NormalTok{chas =}\StringTok{ }\KeywordTok{factor}\NormalTok{(Boston}\OperatorTok{$}\NormalTok{chas, }\DataTypeTok{labels=} \KeywordTok{c}\NormalTok{(}\StringTok{"N"}\NormalTok{,}\StringTok{"Y"}\NormalTok{))}
\KeywordTok{contrasts}\NormalTok{(Boston}\OperatorTok{$}\NormalTok{chas)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Y
## N 0
## Y 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.zn =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{zn, }\DataTypeTok{data =}\NormalTok{ Boston)}
\KeywordTok{summary}\NormalTok{(lm.zn)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ zn, data = Boston)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -4.429 -4.222 -2.620  1.250 84.523 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  4.45369    0.41722  10.675  < 2e-16 ***
## zn          -0.07393    0.01609  -4.594 5.51e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.435 on 504 degrees of freedom
## Multiple R-squared:  0.04019,    Adjusted R-squared:  0.03828 
## F-statistic:  21.1 on 1 and 504 DF,  p-value: 5.506e-06
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{attach}\NormalTok{(Boston)}
\NormalTok{lm.indus =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{indus)}
\KeywordTok{summary}\NormalTok{(lm.indus)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ indus)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -11.972  -2.698  -0.736   0.712  81.813 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -2.06374    0.66723  -3.093  0.00209 ** 
## indus        0.50978    0.05102   9.991  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.866 on 504 degrees of freedom
## Multiple R-squared:  0.1653, Adjusted R-squared:  0.1637 
## F-statistic: 99.82 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.chas =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{chas) }
\KeywordTok{summary}\NormalTok{(lm.chas)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ chas)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.738 -3.661 -3.435  0.018 85.232 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   3.7444     0.3961   9.453   <2e-16 ***
## chasY        -1.8928     1.5061  -1.257    0.209    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.597 on 504 degrees of freedom
## Multiple R-squared:  0.003124,   Adjusted R-squared:  0.001146 
## F-statistic: 1.579 on 1 and 504 DF,  p-value: 0.2094
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.nox =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{nox)}
\KeywordTok{summary}\NormalTok{(lm.nox)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ nox)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -12.371  -2.738  -0.974   0.559  81.728 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  -13.720      1.699  -8.073 5.08e-15 ***
## nox           31.249      2.999  10.419  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.81 on 504 degrees of freedom
## Multiple R-squared:  0.1772, Adjusted R-squared:  0.1756 
## F-statistic: 108.6 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.rm =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{rm)}
\KeywordTok{summary}\NormalTok{(lm.rm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ rm)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.604 -3.952 -2.654  0.989 87.197 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   20.482      3.365   6.088 2.27e-09 ***
## rm            -2.684      0.532  -5.045 6.35e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.401 on 504 degrees of freedom
## Multiple R-squared:  0.04807,    Adjusted R-squared:  0.04618 
## F-statistic: 25.45 on 1 and 504 DF,  p-value: 6.347e-07
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.age =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{age)}
\KeywordTok{summary}\NormalTok{(lm.age)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ age)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.789 -4.257 -1.230  1.527 82.849 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -3.77791    0.94398  -4.002 7.22e-05 ***
## age          0.10779    0.01274   8.463 2.85e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.057 on 504 degrees of freedom
## Multiple R-squared:  0.1244, Adjusted R-squared:  0.1227 
## F-statistic: 71.62 on 1 and 504 DF,  p-value: 2.855e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.age =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{age)}
\KeywordTok{summary}\NormalTok{(lm.age)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ age)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.789 -4.257 -1.230  1.527 82.849 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -3.77791    0.94398  -4.002 7.22e-05 ***
## age          0.10779    0.01274   8.463 2.85e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.057 on 504 degrees of freedom
## Multiple R-squared:  0.1244, Adjusted R-squared:  0.1227 
## F-statistic: 71.62 on 1 and 504 DF,  p-value: 2.855e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.dis =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{dis)}
\KeywordTok{summary}\NormalTok{(lm.dis)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ dis)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.708 -4.134 -1.527  1.516 81.674 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   9.4993     0.7304  13.006   <2e-16 ***
## dis          -1.5509     0.1683  -9.213   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.965 on 504 degrees of freedom
## Multiple R-squared:  0.1441, Adjusted R-squared:  0.1425 
## F-statistic: 84.89 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.rad =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{rad)}
\KeywordTok{summary}\NormalTok{(lm.rad)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ rad)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -10.164  -1.381  -0.141   0.660  76.433 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -2.28716    0.44348  -5.157 3.61e-07 ***
## rad          0.61791    0.03433  17.998  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.718 on 504 degrees of freedom
## Multiple R-squared:  0.3913, Adjusted R-squared:   0.39 
## F-statistic: 323.9 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.tax =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{tax)}
\KeywordTok{summary}\NormalTok{(lm.tax)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ tax)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -12.513  -2.738  -0.194   1.065  77.696 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -8.528369   0.815809  -10.45   <2e-16 ***
## tax          0.029742   0.001847   16.10   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.997 on 504 degrees of freedom
## Multiple R-squared:  0.3396, Adjusted R-squared:  0.3383 
## F-statistic: 259.2 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.ptratio =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{ptratio)}
\KeywordTok{summary}\NormalTok{(lm.ptratio)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ ptratio)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -7.654 -3.985 -1.912  1.825 83.353 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -17.6469     3.1473  -5.607 3.40e-08 ***
## ptratio       1.1520     0.1694   6.801 2.94e-11 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.24 on 504 degrees of freedom
## Multiple R-squared:  0.08407,    Adjusted R-squared:  0.08225 
## F-statistic: 46.26 on 1 and 504 DF,  p-value: 2.943e-11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.black =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{black)}
\KeywordTok{summary}\NormalTok{(lm.black)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ black)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.756  -2.299  -2.095  -1.296  86.822 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 16.553529   1.425903  11.609   <2e-16 ***
## black       -0.036280   0.003873  -9.367   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.946 on 504 degrees of freedom
## Multiple R-squared:  0.1483, Adjusted R-squared:  0.1466 
## F-statistic: 87.74 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.lstat =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{lstat)}
\KeywordTok{summary}\NormalTok{(lm.lstat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ lstat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.925  -2.822  -0.664   1.079  82.862 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -3.33054    0.69376  -4.801 2.09e-06 ***
## lstat        0.54880    0.04776  11.491  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.664 on 504 degrees of freedom
## Multiple R-squared:  0.2076, Adjusted R-squared:  0.206 
## F-statistic:   132 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.medv =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{medv)}
\KeywordTok{summary}\NormalTok{(lm.medv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ medv)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.071 -4.022 -2.343  1.298 80.957 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 11.79654    0.93419   12.63   <2e-16 ***
## medv        -0.36316    0.03839   -9.46   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.934 on 504 degrees of freedom
## Multiple R-squared:  0.1508, Adjusted R-squared:  0.1491 
## F-statistic: 89.49 on 1 and 504 DF,  p-value: < 2.2e-16
\end{verbatim}

All of the predictors, except chas, have significant association with
the response.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(lm.medv)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-32-1.pdf}
\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-32-2.pdf}
\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-32-3.pdf}
\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-32-4.pdf}
Like in this linear regression, you can see most of the residuals is
quiet small, and the line fit the data, too.

\hypertarget{b-3}{%
\subsubsection{(15.b)}\label{b-3}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.all =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\NormalTok{., }\DataTypeTok{data=}\NormalTok{Boston)}
\KeywordTok{summary}\NormalTok{(lm.all)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ ., data = Boston)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.924 -2.120 -0.353  1.019 75.051 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  17.033228   7.234903   2.354 0.018949 *  
## zn            0.044855   0.018734   2.394 0.017025 *  
## indus        -0.063855   0.083407  -0.766 0.444294    
## chasY        -0.749134   1.180147  -0.635 0.525867    
## nox         -10.313535   5.275536  -1.955 0.051152 .  
## rm            0.430131   0.612830   0.702 0.483089    
## age           0.001452   0.017925   0.081 0.935488    
## dis          -0.987176   0.281817  -3.503 0.000502 ***
## rad           0.588209   0.088049   6.680 6.46e-11 ***
## tax          -0.003780   0.005156  -0.733 0.463793    
## ptratio      -0.271081   0.186450  -1.454 0.146611    
## black        -0.007538   0.003673  -2.052 0.040702 *  
## lstat         0.126211   0.075725   1.667 0.096208 .  
## medv         -0.198887   0.060516  -3.287 0.001087 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.439 on 492 degrees of freedom
## Multiple R-squared:  0.454,  Adjusted R-squared:  0.4396 
## F-statistic: 31.47 on 13 and 492 DF,  p-value: < 2.2e-16
\end{verbatim}

zn, dis, rad, black, medv have the p value below 5\%, which can reject
the null hypothesis.

\hypertarget{c-3}{%
\subsubsection{(15.c)}\label{c-3}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x=}\KeywordTok{c}\NormalTok{(}\KeywordTok{coefficients}\NormalTok{(lm.zn)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.indus)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.chas)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.nox)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.rm)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.age)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.dis)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.rad)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.tax)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.ptratio)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.black)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.lstat)[}\DecValTok{2}\NormalTok{],}
      \KeywordTok{coefficients}\NormalTok{(lm.medv)[}\DecValTok{2}\NormalTok{])}
\NormalTok{y=}\KeywordTok{c}\NormalTok{(lm.all}\OperatorTok{$}\NormalTok{coefficients[}\DecValTok{2}\OperatorTok{:}\DecValTok{14}\NormalTok{])}
\KeywordTok{plot}\NormalTok{(x,y)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Assignemnt2-Chapter-3-_files/figure-latex/unnamed-chunk-34-1.pdf}
Coefficient for nox is -10 in univariate model and 31 in multiple model.
And there are some coefficients that have opposite influence on the data
between univariate model and multiple model.

\hypertarget{d-3}{%
\subsubsection{(15.d)}\label{d-3}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.zn =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(zn,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.zn)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(zn, 3))
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -4.821 -4.614 -1.294  0.473 84.130 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)    3.6135     0.3722   9.709  < 2e-16 ***
## poly(zn, 3)1 -38.7498     8.3722  -4.628  4.7e-06 ***
## poly(zn, 3)2  23.9398     8.3722   2.859  0.00442 ** 
## poly(zn, 3)3 -10.0719     8.3722  -1.203  0.22954    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.372 on 502 degrees of freedom
## Multiple R-squared:  0.05824,    Adjusted R-squared:  0.05261 
## F-statistic: 10.35 on 3 and 502 DF,  p-value: 1.281e-06
\end{verbatim}

poly 1 2 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.indus =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(indus,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.indus)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(indus, 3))
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -8.278 -2.514  0.054  0.764 79.713 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(>|t|)    
## (Intercept)        3.614      0.330  10.950  < 2e-16 ***
## poly(indus, 3)1   78.591      7.423  10.587  < 2e-16 ***
## poly(indus, 3)2  -24.395      7.423  -3.286  0.00109 ** 
## poly(indus, 3)3  -54.130      7.423  -7.292  1.2e-12 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.423 on 502 degrees of freedom
## Multiple R-squared:  0.2597, Adjusted R-squared:  0.2552 
## F-statistic: 58.69 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 2 3 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.rm =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(rm,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.rm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(rm, 3))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -18.485  -3.468  -2.221  -0.015  87.219 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept)    3.6135     0.3703   9.758  < 2e-16 ***
## poly(rm, 3)1 -42.3794     8.3297  -5.088 5.13e-07 ***
## poly(rm, 3)2  26.5768     8.3297   3.191  0.00151 ** 
## poly(rm, 3)3  -5.5103     8.3297  -0.662  0.50858    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.33 on 502 degrees of freedom
## Multiple R-squared:  0.06779,    Adjusted R-squared:  0.06222 
## F-statistic: 12.17 on 3 and 502 DF,  p-value: 1.067e-07
\end{verbatim}

poly 1 2 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.nox =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(nox,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.nox)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(nox, 3))
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.110 -2.068 -0.255  0.739 78.302 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)     3.6135     0.3216  11.237  < 2e-16 ***
## poly(nox, 3)1  81.3720     7.2336  11.249  < 2e-16 ***
## poly(nox, 3)2 -28.8286     7.2336  -3.985 7.74e-05 ***
## poly(nox, 3)3 -60.3619     7.2336  -8.345 6.96e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.234 on 502 degrees of freedom
## Multiple R-squared:  0.297,  Adjusted R-squared:  0.2928 
## F-statistic: 70.69 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 2 3 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.age =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(age,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.age)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(age, 3))
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -9.762 -2.673 -0.516  0.019 82.842 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)     3.6135     0.3485  10.368  < 2e-16 ***
## poly(age, 3)1  68.1820     7.8397   8.697  < 2e-16 ***
## poly(age, 3)2  37.4845     7.8397   4.781 2.29e-06 ***
## poly(age, 3)3  21.3532     7.8397   2.724  0.00668 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.84 on 502 degrees of freedom
## Multiple R-squared:  0.1742, Adjusted R-squared:  0.1693 
## F-statistic: 35.31 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 2 3 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.dis =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(dis,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.dis)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(dis, 3))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -10.757  -2.588   0.031   1.267  76.378 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)     3.6135     0.3259  11.087  < 2e-16 ***
## poly(dis, 3)1 -73.3886     7.3315 -10.010  < 2e-16 ***
## poly(dis, 3)2  56.3730     7.3315   7.689 7.87e-14 ***
## poly(dis, 3)3 -42.6219     7.3315  -5.814 1.09e-08 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.331 on 502 degrees of freedom
## Multiple R-squared:  0.2778, Adjusted R-squared:  0.2735 
## F-statistic: 64.37 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 2 3 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.rad =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(rad,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.rad) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(rad, 3))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -10.381  -0.412  -0.269   0.179  76.217 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)     3.6135     0.2971  12.164  < 2e-16 ***
## poly(rad, 3)1 120.9074     6.6824  18.093  < 2e-16 ***
## poly(rad, 3)2  17.4923     6.6824   2.618  0.00912 ** 
## poly(rad, 3)3   4.6985     6.6824   0.703  0.48231    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.682 on 502 degrees of freedom
## Multiple R-squared:    0.4,  Adjusted R-squared:  0.3965 
## F-statistic: 111.6 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 2 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.tax =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(tax,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.tax)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(tax, 3))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.273  -1.389   0.046   0.536  76.950 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)     3.6135     0.3047  11.860  < 2e-16 ***
## poly(tax, 3)1 112.6458     6.8537  16.436  < 2e-16 ***
## poly(tax, 3)2  32.0873     6.8537   4.682 3.67e-06 ***
## poly(tax, 3)3  -7.9968     6.8537  -1.167    0.244    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.854 on 502 degrees of freedom
## Multiple R-squared:  0.3689, Adjusted R-squared:  0.3651 
## F-statistic:  97.8 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 2 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.ptratio =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(ptratio,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.ptratio)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(ptratio, 3))
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -6.833 -4.146 -1.655  1.408 82.697 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(>|t|)    
## (Intercept)          3.614      0.361  10.008  < 2e-16 ***
## poly(ptratio, 3)1   56.045      8.122   6.901 1.57e-11 ***
## poly(ptratio, 3)2   24.775      8.122   3.050  0.00241 ** 
## poly(ptratio, 3)3  -22.280      8.122  -2.743  0.00630 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 8.122 on 502 degrees of freedom
## Multiple R-squared:  0.1138, Adjusted R-squared:  0.1085 
## F-statistic: 21.48 on 3 and 502 DF,  p-value: 4.171e-13
\end{verbatim}

poly 1 2 3 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.black =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(black,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.black)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(black, 3))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.096  -2.343  -2.128  -1.439  86.790 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(>|t|)    
## (Intercept)       3.6135     0.3536  10.218   <2e-16 ***
## poly(black, 3)1 -74.4312     7.9546  -9.357   <2e-16 ***
## poly(black, 3)2   5.9264     7.9546   0.745    0.457    
## poly(black, 3)3  -4.8346     7.9546  -0.608    0.544    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.955 on 502 degrees of freedom
## Multiple R-squared:  0.1498, Adjusted R-squared:  0.1448 
## F-statistic: 29.49 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.lstat =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(lstat,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.lstat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(lstat, 3))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.234  -2.151  -0.486   0.066  83.353 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(>|t|)    
## (Intercept)       3.6135     0.3392  10.654   <2e-16 ***
## poly(lstat, 3)1  88.0697     7.6294  11.543   <2e-16 ***
## poly(lstat, 3)2  15.8882     7.6294   2.082   0.0378 *  
## poly(lstat, 3)3 -11.5740     7.6294  -1.517   0.1299    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 7.629 on 502 degrees of freedom
## Multiple R-squared:  0.2179, Adjusted R-squared:  0.2133 
## F-statistic: 46.63 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 2 important

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm.medv =}\StringTok{ }\KeywordTok{lm}\NormalTok{(crim}\OperatorTok{~}\KeywordTok{poly}\NormalTok{(medv,}\DecValTok{3}\NormalTok{))}
\KeywordTok{summary}\NormalTok{(lm.medv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = crim ~ poly(medv, 3))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -24.427  -1.976  -0.437   0.439  73.655 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(>|t|)    
## (Intercept)       3.614      0.292  12.374  < 2e-16 ***
## poly(medv, 3)1  -75.058      6.569 -11.426  < 2e-16 ***
## poly(medv, 3)2   88.086      6.569  13.409  < 2e-16 ***
## poly(medv, 3)3  -48.033      6.569  -7.312 1.05e-12 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.569 on 502 degrees of freedom
## Multiple R-squared:  0.4202, Adjusted R-squared:  0.4167 
## F-statistic: 121.3 on 3 and 502 DF,  p-value: < 2.2e-16
\end{verbatim}

poly 1 2 3 important


\end{document}
